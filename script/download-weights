#!/usr/bin/env python

import os
import argparse
import torch
import json
from diffusers import StableDiffusionPipeline
from transformers import CLIPTextModel, CLIPTokenizer

parser = argparse.ArgumentParser()
parser.add_argument(
    "--auth_token",
    required=True,
    help="Authentication token from Huggingface for downloaging weights.",
)

args = parser.parse_args()
os.makedirs("pretrain/diffusers-cache", exist_ok=True)
os.makedirs("pretrain/tokenizer", exist_ok=True)
os.makedirs("pretrain/text_encoder", exist_ok=True)
pretrained_model_name_or_path = "CompVis/stable-diffusion-v1-4"
tokenizer = CLIPTokenizer.from_pretrained(
    pretrained_model_name_or_path,
    subfolder="tokenizer",
    cache_dir="pretrain/tokenizer",
    use_auth_token=args.auth_token,
)

text_encoder = CLIPTextModel.from_pretrained(
    pretrained_model_name_or_path,
    subfolder="text_encoder",
    cache_dir="pretrain/text_encoder",
    use_auth_token=args.auth_token,
)

# pipe = StableDiffusionPipeline.from_pretrained(
#     pretrained_model_name_or_path,
#     cache_dir="pretrain/diffuser",
#     torch_dtype=torch.float16,
#     text_encoder=text_encoder,
#     tokenizer=tokenizer,
#     use_auth_token=args.auth_token,
# )

pipe = StableDiffusionPipeline.from_pretrained(
    pretrained_model_name_or_path,
    cache_dir="pretrain/diffusers-cache",
    torch_dtype=torch.float16,
    use_auth_token=args.auth_token,
)

print("All done!") # The permission of the cache-dir may need to change for the demo
